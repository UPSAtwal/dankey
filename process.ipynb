{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('memegenerator.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meme ID</th>\n",
       "      <th>Archived URL</th>\n",
       "      <th>Base Meme Name</th>\n",
       "      <th>Meme Page URL</th>\n",
       "      <th>MD5 Hash</th>\n",
       "      <th>File Size (In Bytes)</th>\n",
       "      <th>Alternate Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10509464</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Spiderman Approves</td>\n",
       "      <td>http://memegenerator.net/instance/10509464</td>\n",
       "      <td>5be4b65cc32d3a57be5b6693bb519155</td>\n",
       "      <td>24093.0</td>\n",
       "      <td>seems legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12285257</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Alright Then Business Kid</td>\n",
       "      <td>http://memegenerator.net/instance/12285257</td>\n",
       "      <td>e2eef6626b3fdb369df23a5fabd99df4</td>\n",
       "      <td>25513.0</td>\n",
       "      <td>Fret not I stayed at a Holiday Inn Express las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20612245</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Archer</td>\n",
       "      <td>http://memegenerator.net/instance/20612245</td>\n",
       "      <td>a6b7db4574325013f05bf1aabdcaeded</td>\n",
       "      <td>31157.0</td>\n",
       "      <td>hello airplanes? yeah, this is blimps. Yeah, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20614628</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>http://webarchive.loc.gov/all/0/http://memegen...</td>\n",
       "      <td>be75a0451f607d65df43813257d90f7a</td>\n",
       "      <td>50056.0</td>\n",
       "      <td>LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24194267</td>\n",
       "      <td>http://webarchive.loc.gov/all/19960101000000-2...</td>\n",
       "      <td>One Does Not Simply</td>\n",
       "      <td>http://memegenerator.net/instance/24194267</td>\n",
       "      <td>2437b5ae9c4741c2e6f249f3f731dee2</td>\n",
       "      <td>24209.0</td>\n",
       "      <td>one does not simply  put toothpaste back in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Meme ID                                       Archived URL  \\\n",
       "0  10509464  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "1  12285257  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "2  20612245  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "3  20614628  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "4  24194267  http://webarchive.loc.gov/all/19960101000000-2...   \n",
       "\n",
       "              Base Meme Name  \\\n",
       "0         Spiderman Approves   \n",
       "1  Alright Then Business Kid   \n",
       "2                     Archer   \n",
       "3               Futurama Fry   \n",
       "4        One Does Not Simply   \n",
       "\n",
       "                                       Meme Page URL  \\\n",
       "0         http://memegenerator.net/instance/10509464   \n",
       "1         http://memegenerator.net/instance/12285257   \n",
       "2         http://memegenerator.net/instance/20612245   \n",
       "3  http://webarchive.loc.gov/all/0/http://memegen...   \n",
       "4         http://memegenerator.net/instance/24194267   \n",
       "\n",
       "                           MD5 Hash  File Size (In Bytes)  \\\n",
       "0  5be4b65cc32d3a57be5b6693bb519155               24093.0   \n",
       "1  e2eef6626b3fdb369df23a5fabd99df4               25513.0   \n",
       "2  a6b7db4574325013f05bf1aabdcaeded               31157.0   \n",
       "3  be75a0451f607d65df43813257d90f7a               50056.0   \n",
       "4  2437b5ae9c4741c2e6f249f3f731dee2               24209.0   \n",
       "\n",
       "                                      Alternate Text  \n",
       "0                                        seems legit  \n",
       "1  Fret not I stayed at a Holiday Inn Express las...  \n",
       "2  hello airplanes? yeah, this is blimps. Yeah, y...  \n",
       "3  LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...  \n",
       "4  one does not simply  put toothpaste back in th...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Meme ID', 'Archived URL', 'MD5 Hash', 'File Size (In Bytes)'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Meme Name</th>\n",
       "      <th>Meme Page URL</th>\n",
       "      <th>Alternate Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiderman Approves</td>\n",
       "      <td>http://memegenerator.net/instance/10509464</td>\n",
       "      <td>seems legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alright Then Business Kid</td>\n",
       "      <td>http://memegenerator.net/instance/12285257</td>\n",
       "      <td>Fret not I stayed at a Holiday Inn Express las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Archer</td>\n",
       "      <td>http://memegenerator.net/instance/20612245</td>\n",
       "      <td>hello airplanes? yeah, this is blimps. Yeah, y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Futurama Fry</td>\n",
       "      <td>http://webarchive.loc.gov/all/0/http://memegen...</td>\n",
       "      <td>LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One Does Not Simply</td>\n",
       "      <td>http://memegenerator.net/instance/24194267</td>\n",
       "      <td>one does not simply  put toothpaste back in th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Base Meme Name  \\\n",
       "0         Spiderman Approves   \n",
       "1  Alright Then Business Kid   \n",
       "2                     Archer   \n",
       "3               Futurama Fry   \n",
       "4        One Does Not Simply   \n",
       "\n",
       "                                       Meme Page URL  \\\n",
       "0         http://memegenerator.net/instance/10509464   \n",
       "1         http://memegenerator.net/instance/12285257   \n",
       "2         http://memegenerator.net/instance/20612245   \n",
       "3  http://webarchive.loc.gov/all/0/http://memegen...   \n",
       "4         http://memegenerator.net/instance/24194267   \n",
       "\n",
       "                                      Alternate Text  \n",
       "0                                        seems legit  \n",
       "1  Fret not I stayed at a Holiday Inn Express las...  \n",
       "2  hello airplanes? yeah, this is blimps. Yeah, y...  \n",
       "3  LEGS IN COVER. TOO HOT. LEGS OUT OF COVER. TOO...  \n",
       "4  one does not simply  put toothpaste back in th...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_headers = ['file_name', 'link', 'text', 'text2', 'sentiment', 'sarcasm', 'offensive', 'motivational', 'positive/negative']\n",
    "df2 = pd.read_excel('data_7000_actual.xlsx', header=None, names=custom_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>text2</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_year_2r94rv.jpg</td>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_year_10-year-challenge_1547788782.jpeg</td>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>The best of #10 YearChallenge! Completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10_year_10yearchallenge-5c75f8b946e0fb0001edc7...</td>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>Sam Thorne @Strippin ( Follow Follow Saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10_year_10-year-challenge-sweet-dee-edition-40...</td>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>10 Year Challenge - Sweet Dee Edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10_year_10-year-challenge-with-no-filter-47-hi...</td>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name  \\\n",
       "0                                 10_year_2r94rv.jpg   \n",
       "1          10_year_10-year-challenge_1547788782.jpeg   \n",
       "2  10_year_10yearchallenge-5c75f8b946e0fb0001edc7...   \n",
       "3  10_year_10-year-challenge-sweet-dee-edition-40...   \n",
       "4  10_year_10-year-challenge-with-no-filter-47-hi...   \n",
       "\n",
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   \n",
       "1  The best of #10 YearChallenge! Completed in le...   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...   \n",
       "3             10 Year Challenge - Sweet Dee Edition    \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   \n",
       "\n",
       "                                               text2   sentiment  \\\n",
       "0  LOOK THERE MY FRIEND LIGHTYEAR NOW ALL SOHALIK...   hilarious   \n",
       "1  The best of #10 YearChallenge! Completed in le...   not_funny   \n",
       "2  Sam Thorne @Strippin ( Follow Follow Saw every...  very_funny   \n",
       "3             10 Year Challenge - Sweet Dee Edition   very_funny   \n",
       "4  10 YEAR CHALLENGE WITH NO FILTER 47 Hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['file_name', 'text2', ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text']=df2['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>look there my friend lightyear now all sohalik...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>the best of #10 yearchallenge! completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>sam thorne @strippin ( follow follow saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 year challenge - sweet dee edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 year challenge with no filter 47 hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text   sentiment  \\\n",
       "0  look there my friend lightyear now all sohalik...   hilarious   \n",
       "1  the best of #10 yearchallenge! completed in le...   not_funny   \n",
       "2  sam thorne @strippin ( follow follow saw every...  very_funny   \n",
       "3             10 year challenge - sweet dee edition   very_funny   \n",
       "4  10 year challenge with no filter 47 hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6520 entries, 0 to 6519\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   link               6520 non-null   object\n",
      " 1   text               6355 non-null   object\n",
      " 2   sentiment          6520 non-null   object\n",
      " 3   sarcasm            6520 non-null   object\n",
      " 4   offensive          6520 non-null   object\n",
      " 5   motivational       6520 non-null   object\n",
      " 6   positive/negative  6520 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 356.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"shutup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m952.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/12/dd/f17b11a93a9ca27728e12512d167eb1281c151c4c6881d3ab59eb58f4127/transformers-4.35.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from sentence_transformers)\n",
      "  Obtaining dependency information for tqdm from https://files.pythonhosted.org/packages/00/e5/f12a80907d0884e6dff9c16d0c0114d81b8cd07dc3ae54c5e962cc83037e/tqdm-4.66.1-py3-none-any.whl.metadata\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/ee/9d/85614d94b24f751d175110753ae8a8cb10e7e533a9289bb493f2f4db8bcd/torch-2.1.1-cp39-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torch-2.1.1-cp39-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/a7/2e/5677e79d26e62f7cf0b98c3781f82cdd51dfb0bf71e7bb03ad176c5f1adc/torchvision-0.16.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading torchvision-0.16.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from sentence_transformers) (1.11.3)\n",
      "Collecting nltk (from sentence_transformers)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-macosx_11_0_arm64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/38/f6/06d7489a9f1b2112a640b3272abd43319d0ee625f26efafb350106893c19/huggingface_hub-0.19.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.19.3-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence_transformers)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/81/54/84d42a0bee35edba99dee7b59a8d4970eccdd44b99fe728ed912106fc781/filelock-3.13.1-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.4.0->sentence_transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Collecting sympy (from torch>=1.6.0->sentence_transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Collecting networkx (from torch>=1.6.0->sentence_transformers)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/d5/f0/8fbc882ca80cf077f1b246c0e3c3465f7f415439bdea6b899f6b19f61f70/networkx-3.2.1-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/cd/98/999f0456bdb4124b3d0a7f1d8b6d50979536f5df9856e597580dd9a6d3ff/regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/9e/2d/35a9f9378962fd954cd097efc0d3b7beee86c12d4e61cf6199bdef58e091/tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/8b/46/91ae7e92277604f8a3457b59d1238ddaffc59e7c2804ac4cb9fd670d58e2/safetensors-0.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading safetensors-0.4.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/riyasachdeva/anaconda3/envs/ml/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading huggingface_hub-0.19.3-py3-none-any.whl (311 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.1-cp39-none-macosx_11_0_arm64.whl (59.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.6/59.6 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.16.1-cp39-cp39-macosx_11_0_arm64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.10.3-cp39-cp39-macosx_11_0_arm64.whl (291 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.0/291.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.0-cp39-cp39-macosx_11_0_arm64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.9/425.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=89647b3d3c9defc9990d96eb37655e4f3fc37474dda9c4e34ab0ad1814886413\n",
      "  Stored in directory: /Users/riyasachdeva/Library/Caches/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: sentencepiece, mpmath, tqdm, sympy, safetensors, regex, networkx, fsspec, filelock, torch, nltk, huggingface-hub, torchvision, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed filelock-3.13.1 fsspec-2023.10.0 huggingface-hub-0.19.3 mpmath-1.3.0 networkx-3.2.1 nltk-3.8.1 regex-2023.10.3 safetensors-0.4.0 sentence_transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.15.0 torch-2.1.1 torchvision-0.16.1 tqdm-4.66.1 transformers-4.35.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57652 entries, 0 to 57651\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Base Meme Name  57645 non-null  object\n",
      " 1   Meme Page URL   57377 non-null  object\n",
      " 2   Alternate Text  57347 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Alternate Text'] = df['Alternate Text'].apply(lambda x: str(x) if x is not None else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57652 entries, 0 to 57651\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Base Meme Name  57645 non-null  object\n",
      " 1   Meme Page URL   57377 non-null  object\n",
      " 2   Alternate Text  57652 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57652 entries, 0 to 57651\n",
      "Data columns (total 3 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   Base Meme Name  57645 non-null  object\n",
      " 1   Meme Page URL   57377 non-null  object\n",
      " 2   Alternate Text  57652 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar meme: Hello shut up\n"
     ]
    }
   ],
   "source": [
    "#dataset 1\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Universal Sentence Encoder\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode messages and meme texts\n",
    "message_embedding = model.encode(text)\n",
    "meme_embeddings = model.encode(df['Alternate Text'].astype(str))\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = util.pytorch_cos_sim(message_embedding, meme_embeddings)[0]\n",
    "\n",
    "# Find the index of the most similar meme\n",
    "most_similar_index = similarities.argmax().item()\n",
    "\n",
    "# Get the most similar meme text\n",
    "most_similar_meme = df['Alternate Text'][most_similar_index]\n",
    "\n",
    "print(\"Most similar meme:\", most_similar_meme)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output from dataset 2\n",
    "\n",
    "# Load the Universal Sentence Encoder\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode messages and meme texts\n",
    "message_embedding = model.encode(text)\n",
    "meme_embeddings = model.encode(df['Alternate Text'].tolist)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarities = util.pytorch_cos_sim(message_embedding, meme_embeddings)[0]\n",
    "\n",
    "# Find the index of the most similar meme\n",
    "most_similar_index = similarities.argmax().item()\n",
    "\n",
    "# Get the most similar meme text\n",
    "most_similar_meme = df['Alternate Text'][most_similar_index]\n",
    "\n",
    "print(\"Most similar meme:\", most_similar_meme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>offensive</th>\n",
       "      <th>motivational</th>\n",
       "      <th>positive/negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://i.imgflip.com/2r94rv.jpg</td>\n",
       "      <td>look there my friend lightyear now all sohalik...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://spiderimg.amarujala.com/assets/images/...</td>\n",
       "      <td>the best of #10 yearchallenge! completed in le...</td>\n",
       "      <td>not_funny</td>\n",
       "      <td>general</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...</td>\n",
       "      <td>sam thorne @strippin ( follow follow saw every...</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>not_sarcastic</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pics.conservativememes.com/10-year-cha...</td>\n",
       "      <td>10 year challenge - sweet dee edition</td>\n",
       "      <td>very_funny</td>\n",
       "      <td>twisted_meaning</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>motivational</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pics.me.me/10-year-challenge-with-no-f...</td>\n",
       "      <td>10 year challenge with no filter 47 hilarious ...</td>\n",
       "      <td>hilarious</td>\n",
       "      <td>very_twisted</td>\n",
       "      <td>very_offensive</td>\n",
       "      <td>not_motivational</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0                   https://i.imgflip.com/2r94rv.jpg   \n",
       "1  https://spiderimg.amarujala.com/assets/images/...   \n",
       "2  https://www.lifewire.com/thmb/8wNfd94_meE9X2cp...   \n",
       "3  https://pics.conservativememes.com/10-year-cha...   \n",
       "4  https://pics.me.me/10-year-challenge-with-no-f...   \n",
       "\n",
       "                                                text   sentiment  \\\n",
       "0  look there my friend lightyear now all sohalik...   hilarious   \n",
       "1  the best of #10 yearchallenge! completed in le...   not_funny   \n",
       "2  sam thorne @strippin ( follow follow saw every...  very_funny   \n",
       "3             10 year challenge - sweet dee edition   very_funny   \n",
       "4  10 year challenge with no filter 47 hilarious ...   hilarious   \n",
       "\n",
       "           sarcasm       offensive      motivational positive/negative  \n",
       "0          general   not_offensive  not_motivational          positive  \n",
       "1          general   not_offensive      motivational          positive  \n",
       "2    not_sarcastic   not_offensive  not_motivational          positive  \n",
       "3  twisted_meaning  very_offensive      motivational          positive  \n",
       "4     very_twisted  very_offensive  not_motivational           neutral  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose one\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
